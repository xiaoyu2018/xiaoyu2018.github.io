<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>D2L: Basic Pytorch</title><meta name="description" content="while(true) me.Learn();"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/tom.jpg"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/post.css"><link rel="stylesheet" href="/style/themes/highlight-theme-light.css"><script src="/js/highlight.pack.js"></script><meta name="description" content="
Basic Pytorch
模型构造

import torch 
from torch import nn
net=nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))
X=torch.normal(0,1,size=(1,20))
print(net(X))

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.rand_weight=torch.randn((20,64),requires_grad=False,dtype=torch.float32)
        self.hidden=nn.Sequenti.."><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Xavier's blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Xavier's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"><div class="is-full-height" id="postTopic"><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">D2L: Basic Pytorch</p><p class="is-full-height is-flex-shrink-0 is-flex is-align-items-center is-justify-content-center">Click back to the top</p></div></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><main class="container is-max-widescreen content section post-page pt-4 px-4"><div class="columns is-flex-desktop is-justify-content-center is-flex-direction-row-reverse"><div class="column is-3 is-hidden-mobile"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Basic-Pytorch"><span class="toc-text">Basic Pytorch</span></a></li></ol></div><div class="column is-9"><header class="my-4"><a href="/tags/Dive-Into-Deep-Learning"><i class="tag post-item-tag">Dive-Into-Deep-Learning</i></a><a href="/tags/Neural-Network"><i class="tag post-item-tag">Neural-Network</i></a></header><h1 class="mt-0 mb-1 is-family-serif" id="postTitle">D2L: Basic Pytorch</h1><time class="has-text-grey" datetime="2021-11-28T09:15:03.446Z">2021-11-28</time><article class="mt-2 post-content"><p><img src="/images/d2l/1/cover.png" alt="$cover"></p>
<h1 id="Basic-Pytorch"><a href="#Basic-Pytorch" class="headerlink" title="Basic Pytorch"></a>Basic Pytorch</h1><ul>
<li>模型构造</li>
</ul>
<pre><code class="python">import torch 
from torch import nn
net=nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))
X=torch.normal(0,1,size=(1,20))
print(net(X))

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.rand_weight=torch.randn((20,64),requires_grad=False,dtype=torch.float32)
        self.hidden=nn.Sequential(nn.Linear(64,128),nn.ReLU(),nn.Linear(128,256))
        self.out=nn.Linear(256,10)

    def forward(self,X):
        X=X@self.rand_weight+1
        X=nn.ReLU()(self.hidden(X))
        X=self.out(X)
        # 下面这个过程流不会计入计算图
        with torch.no_grad():
            while torch.abs(X).sum()&gt;1:
                X/=2
        return X.sum()

net=MLP()
print(net(X))
</code></pre>
<ul>
<li>参数管理</li>
</ul>
<pre><code class="python">import torch
from torch import nn

net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))
X=torch.rand(size=(2,4))

# 访问参数
# 访问网络中每一层，以及如何访问层中的参数
print(net[0].state_dict(),net[1],net[2].bias.data)
# 网络中的参数包括data和grad两部分，在这没做反向传播呢，所以梯度为None
print(net[2].weight.grad==None)
# 将整个网络信息打印
print(net)

# 初始化参数
# pytorch已经为我们做了比较好的默认初始化
def init_xavier(m):
    if(type(m)==nn.Linear):
        nn.init.xavier_normal_(m.weight)
        nn.init.zeros_(m.bias)
def init_42(m):
    nn.init.constant_(m.weight,42)
    nn.init.constant_(m.bias,42)
# 将初始化函数应用到net每一个子层，不止可以用在初始化上
net[0].apply(init_xavier)
print([i for i in net[0].parameters()])
net[2].apply(init_42)
print(net[2].weight,net[2].bias)

# 更暴力的方法
net[0].weight.data[:]+=100
print(net[0].weight.data)

# 参数绑定
# 让某几层共享同样的参数
shared=nn.Linear(8,8)
net=nn.Sequential(nn.Linear(4,8),nn.ReLU(),shared,nn.ReLU(),shared,nn.Sigmoid(),nn.Linear(8,1))
print(net[2]==shared)
print(net[2].weight.data==net[4].weight.data)
</code></pre>
<ul>
<li>自定义层</li>
</ul>
<pre><code class="python">import torch
from torch import nn

# 自定义层和自定义模型没本质区别
class CenteredLayer(nn.Module):
    def __init__(self):
        super().__init__()
    
    def forward(self,X):
        
        return X-X.mean()

layer=CenteredLayer()
print(layer(torch.tensor([1,2,3,4],dtype=torch.float32)))

# 带有参数的层
class PrameterizedLayer(nn.Module):
    def __init__(self,in_dim,out_dim):
        super().__init__()
        self.w=nn.Parameter(torch.randn((in_dim,out_dim)))
        self.b=nn.Parameter(torch.randn((out_dim)))

    def forward(self,X):
        
        return X@self.w.data+self.b.data

net=PrameterizedLayer(2,8)
print(net(torch.tensor([[1,2],[2,3],[3,4]],dtype=torch.float32)))
</code></pre>
<ul>
<li>读写文件</li>
</ul>
<pre><code class="python">import torch
from torch import nn

x=torch.arange(4)
# 加载和保存张量
torch.save(x,'x_file')
y=torch.load('x_file')
print(x==y)

# 加载和保存张量组成的数据结构
a=torch.arange(5)
b=torch.arange(5)
torch.save([a,b],"list")
torch.save({'a':a,'b':b},"dict")
# 读取到内存会保持原数据结构
print(torch.load("list"))
print(torch.load("dict"))

# 加载和保存模型的参数
net=nn.Sequential(nn.Conv2d(1,2,5),nn.Flatten(),nn.Linear(288,64))
print(net(torch.normal(0,0.5,size=(1,1,16,16))))
print(net.state_dict())
torch.save(net.state_dict(),'net.params')
new_net=nn.Sequential(nn.Conv2d(1,2,5),nn.Flatten(),nn.Linear(288,64))
new_net.load_state_dict(torch.load('net.params'))
print(new_net==net)

X=torch.normal(0,0.5,size=(1,1,16,16))
print(new_net(X)==net(X))
</code></pre>
</article><section class="jump-container is-flex is-justify-content-space-between my-6"><!-- em is empty placeholder--><em></em><a class="button is-default" href="/2021/11/28/d2l_7/" title="D2L: Numerical Stability &amp; Initialization"><span class="has-text-weight-semibold">Next: D2L: Numerical Stability &amp; Initialization</span><i class="iconfont icon-next ml-2 has-text-grey"></i></a></section><article class="mt-6 comment-container"><script async repo="xiaoyu2018/xiaoyu2018.github.io" src="https://utteranc.es/client.js" issue-term="pathname" theme="preferred-color-scheme"></script></article></div></div></main></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/xiaoyu2018"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Xavier 2021</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/js/post.js"></script></body></html>