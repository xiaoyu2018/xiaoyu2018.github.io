<!DOCTYPE html><html class="appearance-auto" lang="en"><head><meta charset="UTF-8"><title>Xavier's blog</title><meta name="description" content="while(true) me.Learn();"><meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no, initial-scale=1"><!-- Google Analytics --><!-- End Google Analytics -->
<!-- Baidu Analytics --><!-- End Baidu Analytics --><link rel="icon" href="/images/tom.jpg"><link rel="stylesheet" href="/style/common/bulma.css"><link rel="stylesheet" href="/style/base.css"><link rel="stylesheet" href="/style/common/helper.css"><script src="/js/common.js"></script><link rel="stylesheet" href="/style/widget-post-list.css"><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Xavier's blog" type="application/atom+xml">

<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head><body class="is-flex is-flex-direction-column"><header class="header-widget is-flex-shrink-0 is-hidden-mobile"><div class="container is-fullhd is-flex is-justify-content-space-between is-align-items-center is-full-height"><section class="is-hidden-mobile is-flex-shrink-0"><h2><a href="/">Xavier's blog</a></h2></section><h3 class="is-hidden-mobile is-family-serif is-full-height is-flex is-align-items-center is-flex-shrink-0"></h3><aside class="is-flex-shrink-0"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></aside></div></header><header class="is-flex header-widget is-flex-shrink-0 is-align-items-center is-justify-content-center is-hidden-tablet"><h3 class="is-inline-block"><a href="/">Home</a></h3><h3 class="is-inline-block"><a href="/about">About</a></h3><h3 class="is-inline-block"><a href="/archives">Archives</a></h3></header><main><article class="post-container is-flex is-justify-content-center section container is-max-widescreen pt-4 px-2"><div class="columns is-variable is-1-tablet is-3-desktop-only is-2-widescreen is-full-width"><section class="column"><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/d2l/1/cover.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/01/25/d2l_15/"><img class="post-cover-img js-img-fadeIn" src="/images/d2l/1/cover.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Dive-Into-Deep-Learning"><i class="tag post-item-tag">Dive-Into-Deep-Learning</i></a><a href="/tags/Neural-Network"><i class="tag post-item-tag">Neural-Network</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/01/25/d2l_15/">D2L: GoogLeNet</a></h2><time class="has-text-grey" datetime="2022-01-25T03:46:56.930Z">2022-01-25</time><p class="is-flex-grow-2 mt-2">
GoogLeNetBasic knowledge
Inception块
4个路径从不同层面抽取信息，然后再输出通道合并，最终输出高宽与输入相等，要把更多的通道数留给比较重要的通道
要达到相同的输出通道数，Inception块与直接的3x3或5x5卷积相比，参数和计算复杂度更低


GoogLeNet
5个stage（高宽减半一次就是一个stage），9个Inception块


Inception后续具有多个变种
Inception-BN(v2)：使用batch normalization
Inception-v3：修改了inception块
Inception-v4：使用了残差连接



Implementationimport torch
from torch import nn,optim
impo..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/01/25/d2l_15/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/d2l/1/cover.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/01/24/d2l_14/"><img class="post-cover-img js-img-fadeIn" src="/images/d2l/1/cover.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Dive-Into-Deep-Learning"><i class="tag post-item-tag">Dive-Into-Deep-Learning</i></a><a href="/tags/Neural-Network"><i class="tag post-item-tag">Neural-Network</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/01/24/d2l_14/">D2L: NiN</a></h2><time class="has-text-grey" datetime="2022-01-24T08:13:02.319Z">2022-01-24</time><p class="is-flex-grow-2 mt-2">
NiNBasic knowledge
全连接层的问题：
全连接层参数比卷积层的参数多很多，导致很多的内存（显存）及计算带宽占用
全连接层容易带来过拟合


NiN思想：完全不要全连接层
NiN块：
一个卷积层后跟两个起到全连接层的作用的卷积层
起到全连接层的作用的卷积层为1x1步幅为1无填充的卷积层


NiN架构
无全连接层
交替使用NiN块和步幅为2的最大池化层
最后使用全局平均池化层得到输出（通道数是类别数）



Implementationimport torch
from torch import nn,optim

class NiNBlock(nn.Module):
    def __init__(
        self,in_channels,out_channels,
     ..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/01/24/d2l_14/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/d2l/1/cover.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/01/23/d2l_13/"><img class="post-cover-img js-img-fadeIn" src="/images/d2l/1/cover.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Dive-Into-Deep-Learning"><i class="tag post-item-tag">Dive-Into-Deep-Learning</i></a><a href="/tags/Neural-Network"><i class="tag post-item-tag">Neural-Network</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/01/23/d2l_13/">D2L: VGGNet</a></h2><time class="has-text-grey" datetime="2022-01-23T02:58:52.194Z">2022-01-23</time><p class="is-flex-grow-2 mt-2">
VGGNetBasic knowledge
AlexNet的设计很随意，如何变大变深无规律性，VGG探讨了如何对CNN进行扩展
如何更深更大？
更多全连接层（太贵）
更多的卷积层
将卷积层组合成块（VGG）


VGG块
使用小卷积核深网络比大小卷积核浅网络效果好
3x3卷积层（n层、m通道）
2x2最大池化层


VGG架构
多个VGG块后接全连接层
不同次数的重复块得到不同架构（VGG-16、VGG-19等）



Implementationimport torch
from torch import dropout, nn,optim
import d2l
# 返回VGG块

def vgg_block(num_convs,in_channels,out_channels):
    layers..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/01/23/d2l_13/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/d2l/1/cover.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/01/22/d2l_12/"><img class="post-cover-img js-img-fadeIn" src="/images/d2l/1/cover.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Dive-Into-Deep-Learning"><i class="tag post-item-tag">Dive-Into-Deep-Learning</i></a><a href="/tags/Neural-Network"><i class="tag post-item-tag">Neural-Network</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/01/22/d2l_12/">D2L: AlexNet</a></h2><time class="has-text-grey" datetime="2022-01-22T08:05:31.808Z">2022-01-22</time><p class="is-flex-grow-2 mt-2">
AlexNetBasic knowledge
在深度学习之前：
核方法
特征提取
选择核函数
凸优化问题
漂亮的定理


几何学
抽取特征
将计算机视觉问题描述为几何问题（如多相机）
凸优化
漂亮的定理
建立假设模型，若假设满足，效果会很好


特征工程
特征工程（人工特征提取）是关键，不太关心机器学习模型
特征描述子（SIFT、SURF）
视觉词袋（聚类）
最后一般用SVM




AlexNet赢得了2012年ImageNet竞赛的冠军，引起了深度学习的热潮，其本质上是一个更深更大的LeNet
主要改进：
丢弃法
ReLU
MaxPooling
数据增强（截取、调亮度、调色温等）
更深更大




网络结构与复杂度

Implementationimport torch
from torch impo..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/01/22/d2l_12/">Read more</a></section></article><article class="post-item-card"><header class="is-relative is-flex"><div class="post-cover-backdrop is-hidden"><img src="/images/d2l/1/cover.png" alt="loading.."></div><a class="post-cover-link has-text-centered skeleton" href="/2022/01/22/d2l_11/"><img class="post-cover-img js-img-fadeIn" src="/images/d2l/1/cover.png" alt="loading.." data-backdrop="true"></a></header><section class="content post-card-content p-4 pb-5"><header><a href="/tags/Dive-Into-Deep-Learning"><i class="tag post-item-tag">Dive-Into-Deep-Learning</i></a><a href="/tags/Neural-Network"><i class="tag post-item-tag">Neural-Network</i></a></header><h2 class="mt-4 mb-0 is-family-serif"><a href="/2022/01/22/d2l_11/">D2L: LeNet</a></h2><time class="has-text-grey" datetime="2022-01-22T04:20:12.842Z">2022-01-22</time><p class="is-flex-grow-2 mt-2">
LeNetBasic knowledge
最早是用于手写数字识别，识别信件上的邮政编码
网络结构
提出了一个数据集：MNIST
5w个训练数据
1w个测试数据
图像大小 28x28
10类


总结
LeNet是早期成功的神经网络
先使用卷积层学习图片空间信息
然后使用全连接层转换到类别空间



Implementationfrom torch import optim
import torch
from torch import nn
import d2l

# 定义Reshape层
class Reshape(nn.Module):
    
    def forward(self,x):
        return x.view(-1,1,28,28)

net=nn.Sequential(
..</p><a class="button is-default mt-2 has-text-weight-semibold" href="/2022/01/22/d2l_11/">Read more</a></section></article><section class="paginator is-flex is-justify-content-flex-end is-flex-wrap-wrap mt-5"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="iconfont icon-next has-text-grey"></i></a></section></section><aside class="column is-hidden-mobile is-4-tablet is-3-widescreen"><style>.search-widget .search-input {
    border: none;
    outline: none;
    background: transparent;
    color: var(--second-text-color);
}
.search-widget .search-content {
    position: absolute;
    left: 0;
    top: calc(100% - 3px);
    z-index: 2;

    width: 100%;
    height: 0;
    max-height: 550px;

    overflow: auto;
    box-sizing: border-box;

    background: var(--top-bar-bg-color);
    backdrop-filter: blur(var(--backdropFilter));
    -webkit-backdrop-filter: blur(var(--backdropFilter));

    border-bottom-left-radius: var(--borderRadius);
    border-bottom-right-radius: var(--borderRadius);
    box-shadow: 0 12px 15px rgba(0, 0, 0, 0.08);
}

.search-widget .search-content a:hover h5 {
    color: #3273dc!important;
}
</style><main class="aside-card-container search-widget is-relative"><label for="searchInput"><div class="is-flex px-4" id="searchButton"><i class="iconfont icon--search1 mr-1"></i><input class="search-input is-flex-grow-1" id="searchInput" placeholder="Search everything.."></div></label><section class="search-content content" id="searchContent"></section></main><script>var searchDatabase = []
var searchInputEl = document.getElementById('searchInput')
var searchButtonEl = document.getElementById('searchButton')
var searchResultEl = document.getElementById('searchContent')

searchInputEl.oninput = function (evt) {
    var searchValue = evt.srcElement.value
    var haveSearchValue = Boolean(searchValue.trim())
    if (!haveSearchValue) {
        searchResultEl.style.height = 0
        searchResultEl.innerHTML = null
        return
    }

    var searchResults = searching(searchValue)

    if (searchResults.length > 0) {
        renderSearchResults(searchResults)
    }
}

function renderSearchResults(results) {
    searchResultEl.innerHTML = null
    var fragment = document.createDocumentFragment()

    results.forEach(function (item) {
        var link = document.createElement('a')
        var title = document.createElement('h5')
        var content = document.createElement('p')

        title.className = 'mb-1'
        title.innerText = item.title
        content.innerText = item.content

        link.href = item.link
        link.appendChild(title)
        link.appendChild(content)
        link.className = 'p-4 is-block'

        fragment.appendChild(link)
    })

    searchResultEl.appendChild(fragment)
    searchResultEl.style.height = 'auto'
}

function searching(inputText) {
    var inputTexts = inputText.split(' ')
    var searchResults = []
    inputTexts.forEach(function (searchKey) {
        var haveSearchValue = Boolean(searchKey.trim())
        if (!haveSearchValue) return

        var key = searchKey.toLowerCase()

        for (var entry of searchDatabase) {
            var title = entry.getElementsByTagName('title')[0].textContent
            var link = entry.getElementsByTagName('link')[0].getAttribute('href')
            var contentWithTags = entry.getElementsByTagName('content')[0].textContent
            var rawContent = contentWithTags.trim().replace(/<[^>]+>/g, '').toLowerCase()

            var LENGTH = 80
            var finalContent = ''
            var contentLength = rawContent.length
            var searchResultIdx = rawContent.indexOf(key)

            var startIdx = searchResultIdx - 20,
                endIdx = startIdx + LENGTH

            if (startIdx < 0) {
                startIdx = 0
                endIdx = 100
            }

            endIdx > contentLength && (endIdx = contentLength)

            finalContent = rawContent.substring(startIdx, endIdx)

            if (title.indexOf(key) > -1 || searchResultIdx > -1) {
                searchResults.push({
                    link: link,
                    title: title,
                    content: finalContent
                })
            }
        }
    })
    return searchResults
}

searchButtonEl.onclick = function () {
    if (searchDatabase.length > 0) return;

    fetch(window.location.href + '/search.xml').then(res => res.text()).then(res => {
        var domparser = new DOMParser
        var doc = domparser.parseFromString(res, 'application/xml')
        searchDatabase = doc.getElementsByTagName('search')[0].children
    })
}</script><main class="aside-card-container profile-widget"><!-- todo: 使用取色工具动态阴影--><section class="is-flex is-flex-direction-column is-justify-content-center is-align-items-center"><section class="is-flex is-justify-content-center avatar is-clipped skeleton"><!-- debug images "https://api.ixiaowai.cn/gqapi/gqapi.php"--><img class="js-img-fadeIn" src="/images/avatar.jpg" alt="user avatar"></section><h3 class="user-name">Xavier</h3><blockquote class="has-text-centered is-relative"><span style="margin-bottom: 5px;">while(true) me.Learn();</span></blockquote><address class="has-text-centered has-text-grey"><i class="iconfont icon-location" style="margin-right: 5px;"></i><span class="has-text-grey">Beijing</span></address></section><section class="sns-container is-flex is-justify-content-center is-align-items-center"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/xiaoyu2018"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section></main><main class="aside-card-container recent-widget"><h3>Recent</h3><ul><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="/images/d2l/1/cover.png" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2022/01/25/d2l_15/">D2L: GoogLeNet</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2022-01-25T03:46:56.930Z">2022-01-25</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="/images/d2l/1/cover.png" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2022/01/24/d2l_14/">D2L: NiN</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2022-01-24T08:13:02.319Z">2022-01-24</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="/images/d2l/1/cover.png" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2022/01/23/d2l_13/">D2L: VGGNet</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2022-01-23T02:58:52.194Z">2022-01-23</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="/images/d2l/1/cover.png" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2022/01/22/d2l_12/">D2L: AlexNet</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2022-01-22T08:05:31.808Z">2022-01-22</time></section></li><li class="is-flex"><!-- change to element replace image placeholder--><img class="js-img-fadeIn" src="/images/d2l/1/cover.png" alt="cover"><!--else--><!--    div.post-img-placeholder--><section class="is-flex-grow-2"><p class="has-text-weight-semibold" style="line-height: 20px; font-size: 14px"><a href="/2022/01/22/d2l_11/">D2L: LeNet</a></p><time class="has-text-weight-semibold has-text-grey" datetime="2022-01-22T04:20:12.842Z">2022-01-22</time></section></li></ul></main><main class="aside-card-container categories-widget category-page"><h3>Categories</h3><section><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/C/">C#</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Genesis/">Genesis</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><span class="category-list-count">19</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/notes/">notes</a><span class="category-list-count">1</span></li></ul></section></main><main class="aside-card-container archives-widget"><h3>Archives</h3><section><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/12/">December 2021</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/11/">November 2021</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/10/">October 2021</a><span class="archive-list-count">2</span></li></ul></section></main><main class="aside-card-container tag-widget"><h3>Tags</h3><section><a href="/tags/typography"><span class="tag post-item-tag" style="margin-bottom: 5px;">typography</span></a><a href="/tags/hexo"><span class="tag post-item-tag" style="margin-bottom: 5px;">hexo</span></a><a href="/tags/Hello"><span class="tag post-item-tag" style="margin-bottom: 5px;">Hello</span></a><a href="/tags/Neural%20Network"><span class="tag post-item-tag" style="margin-bottom: 5px;">Neural Network</span></a><a href="/tags/papers"><span class="tag post-item-tag" style="margin-bottom: 5px;">papers</span></a><a href="/tags/Dive-Into-Deep-Learning"><span class="tag post-item-tag" style="margin-bottom: 5px;">Dive-Into-Deep-Learning</span></a><a href="/tags/Neural-Network"><span class="tag post-item-tag" style="margin-bottom: 5px;">Neural-Network</span></a><a href="/tags/Asynchronous-programming"><span class="tag post-item-tag" style="margin-bottom: 5px;">Asynchronous-programming</span></a><a href="/tags/CS-Threading"><span class="tag post-item-tag" style="margin-bottom: 5px;">CS-Threading</span></a><a href="/tags/Generative-Model"><span class="tag post-item-tag" style="margin-bottom: 5px;">Generative-Model</span></a><a href="/tags/Residual-learning"><span class="tag post-item-tag" style="margin-bottom: 5px;">Residual-learning</span></a><a href="/tags/Seq2Seq-Model"><span class="tag post-item-tag" style="margin-bottom: 5px;">Seq2Seq-Model</span></a><a href="/tags/Computer%20Vision"><span class="tag post-item-tag" style="margin-bottom: 5px;">Computer Vision</span></a></section></main></aside></div></article><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></main><footer class="is-flex is-flex-direction-column is-align-items-center is-flex-shrink-0 is-family-serif"><section class="sns-container"><!-- Github--><a title="github" target="_blank" rel="noopener nofollow" href="//github.com/xiaoyu2018"><i class="iconfont icon-github"></i></a><!-- Ins--><!-- RSS--><!-- 知乎--><!-- 领英--><!-- 脸书--></section><p><span>Copyright ©</span><span> Xavier 2022</span></p><div class="is-flex is-justify-content-center is-flex-wrap-wrap"><p>Powered by Hexo &verbar;&nbsp;</p><p class="is-flex is-justify-content-center"><a title="Hexo theme author" target="_blank" rel="noopener" href="//github.com/haojen">Theme by Haojen&nbsp;</a></p><div style="margin-top: 2px"><a class="github-button" title="github-button" target="_blank" rel="noopener" href="https://github.com/haojen/hexo-theme-Claudia" data-color-scheme="no-preference: light; light: light; dark: dark;" data-show-count="true"></a></div></div><div><span></span></div></footer><script async defer src="https://buttons.github.io/buttons.js"></script><script>$claudia.fadeInImage(null, $claudia.blurBackdropImg)

window.addEventListener('resize', $claudia.throttle(function () {
    var images = document.querySelectorAll('.js-img-fadeIn')

    images.forEach($claudia.blurBackdropImg)
}, 150))</script></body></html>